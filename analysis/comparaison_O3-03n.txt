27,28c27,28
<   Application:			./s13_03
<   Timestamp:			2021-03-01 16:46:24
---
>   Application:			./s13_03n
>   Timestamp:			2021-03-01 16:46:45
50c50
<   Total Time:				0.05 s
---
>   Total Time:				0.03 s
52c52
<   Time spent in innermost loops:	88.89 %
---
>   Time spent in innermost loops:	100 %
54c54
<   Perfect Flow Complexity:		3.98
---
>   Perfect Flow Complexity:		6.15
57c57
<       Potential Speedup:		1.20
---
>       Potential Speedup:		1.18
60c60
<       Potential Speedup:		1.17
---
>       Potential Speedup:		1.18
63,64c63,64
<       Potential Speedup:		5.95
<       Nb Loops to get 80%:		2
---
>       Potential Speedup:		6.15
>       Nb Loops to get 80%:		1
75,76c75,76
<       Number of loops   | 1      | 2      | 
<       Cumulated Speedup | 1.2038 | 1.2038 | 
---
>       Number of loops   | 1      | 
>       Cumulated Speedup | 1.1765 | 
78,79c78
<     s13 - 03 - 5:	1.2038
<     s13 - 03 - 6:	1.2038
---
>     s13 - 03n - 5:	1.1765
82,83c81,82
<       Number of loops   | 1      | 2      | 
<       Cumulated Speedup | 1.1703 | 1.1703 | 
---
>       Number of loops   | 1      | 
>       Cumulated Speedup | 1.1765 | 
85,86c84
<     s13 - 03 - 5:	1.1703
<     s13 - 03 - 6:	1.1703
---
>     s13 - 03n - 5:	1.1765
89,90c87,88
<       Number of loops   | 1      | 2      | 
<       Cumulated Speedup | 3.9791 | 5.9528 | 
---
>       Number of loops   | 1      | 
>       Cumulated Speedup | 6.1538 | 
92,93c90
<     s13 - 03 - 5:	3.9791
<     s13 - 03 - 6:	5.9528
---
>     s13 - 03n - 5:	6.1538
137,144c134,141
<    > 8%                  | 1                     | 88.89                 | 88.89                 |
<    4% to 8%              | 0                     | 0                     | 88.89                 |
<    2% to 4%              | 0                     | 0                     | 88.89                 |
<    1% to 2%              | 0                     | 0                     | 88.89                 |
<    0.5% to 1%            | 0                     | 0                     | 88.89                 |
<    0.25% to 0.5%         | 0                     | 0                     | 88.89                 |
<    0.125% to 0.25%       | 0                     | 0                     | 88.89                 |
<    < 0.125%              | 0                     | 0                     | 88.89                 |
---
>    > 8%                  | 1                     | 100                   | 100                   |
>    4% to 8%              | 0                     | 0                     | 100                   |
>    2% to 4%              | 0                     | 0                     | 100                   |
>    1% to 2%              | 0                     | 0                     | 100                   |
>    0.5% to 1%            | 0                     | 0                     | 100                   |
>    0.25% to 0.5%         | 0                     | 0                     | 100                   |
>    0.125% to 0.25%       | 0                     | 0                     | 100                   |
>    < 0.125%              | 0                     | 0                     | 100                   |
158c155
<    s13                                          | s13_03          | 100          | 0.04       |
---
>    s13                                          | s13_03n         | 100          | 0.03       |
172,173c169
<    5          | s13_03          |                                              | 88.89        |
<    6          | s13_03          |                                              | 11.11        |
---
>    5          | s13_03n         |                                              | 100          |
192c188
<       5.1.1  -  Loop 5 from s13_03
---
>       5.1.1  -  Loop 5 from s13_03n
310c306
< 0% of peak computational performance is used (0.25 out of 32.00 FLOP per cycle (GFLOPS @ 1GHz))
---
> 0% of peak computational performance is used (0.27 out of 32.00 FLOP per cycle (GFLOPS @ 1GHz))
316c312
< By removing them, you can lower the cost of an iteration from 4.00 to 3.00 cycles (1.33x speedup).
---
> By removing them, you can lower the cost of an iteration from 3.75 to 3.00 cycles (1.25x speedup).
327,329c323,325
< Your loop is probably not vectorized.
< Only 18% of vector register length is used (average across all SSE/AVX instructions).
< By vectorizing your loop, you can lower the cost of an iteration from 4.00 to 0.75 cycles (5.33x speedup).
---
> Your loop is not vectorized.
> Only 14% of vector register length is used (average across all SSE/AVX instructions).
> By vectorizing your loop, you can lower the cost of an iteration from 3.75 to 0.75 cycles (5.00x speedup).
332c328
< Store and arithmetical SSE/AVX instructions are used in scalar version (process only one data element in vector registers).
---
> All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).
363,368c359
<  - CVTSS2SD: 1 occurrences
< 
< 
< Workaround
< Pass to your compiler a micro-architecture specialization option:
<  - Please read your compiler manual
---
>  - VCVTSS2SD: 1 occurrences
394c385
<  - CVTSS2SD (FP32 to FP64, scalar): 1 occurrences
---
>  - VCVTSS2SD (FP32 to FP64, scalar): 1 occurrences
435c426
< By removing them, you can lower the cost of an iteration from 3.50 to 2.50 cycles (1.40x speedup).
---
> By removing them, you can lower the cost of an iteration from 3.25 to 2.50 cycles (1.30x speedup).
446,448c437,439
< Your loop is probably not vectorized.
< Only 19% of vector register length is used (average across all SSE/AVX instructions).
< By vectorizing your loop, you can lower the cost of an iteration from 3.50 to 0.47 cycles (7.47x speedup).
---
> Your loop is not vectorized.
> Only 14% of vector register length is used (average across all SSE/AVX instructions).
> By vectorizing your loop, you can lower the cost of an iteration from 3.25 to 0.44 cycles (7.43x speedup).
451c442
< Store and arithmetical SSE/AVX instructions are used in scalar version (process only one data element in vector registers).
---
> All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).
482,487c473
<  - CVTSS2SD: 1 occurrences
< 
< 
< Workaround
< Pass to your compiler a micro-architecture specialization option:
<  - Please read your compiler manual
---
>  - VCVTSS2SD: 1 occurrences
497c483
<  - CVTSS2SD (FP32 to FP64, scalar): 1 occurrences
---
>  - VCVTSS2SD (FP32 to FP64, scalar): 1 occurrences
517,588d502
< 
< 
< 
< 
< 
< 
< 
<       5.1.2  -  Loop 6 from s13_03
<   ========================================================================================
< 
< 
< Warnings:
< Non-innermost loop: analyzing only self part (ignoring child loops).
< This loop has 4 execution paths.
< 
< The presence of multiple execution paths is typically the main/first bottleneck.
< Try to simplify control inside loop: ideally, try to remove all conditional expressions, for example by (if applicable):
<  - hoisting them (moving them outside the loop)
<  - turning them into conditional moves, MIN or MAX
< 
< 
< 
<       5.1.2.1  -  Path 1
<   ----------------------------------------------------------------------------------------
< 
< Warnings:
< This path is accessible from 4 CFG paths (including child blocks)
< 
< 0% of peak computational performance is used (0.00 out of 4.00 FLOP per cycle (GFLOPS @ 1GHz))
< 
<       5.1.2.1.1  -  Vectorization
<   ----------------------------------------------------------------------------------------
< 
< Your loop is not vectorized.
< 4 data elements could be processed at once in vector registers.
< By vectorizing your loop, you can lower the cost of an iteration from 1.50 to 0.37 cycles (4.00x speedup).
< 
< Details
< All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).
< Since your execution units are vector units, only a vectorized loop can use their full power.
< 
< 
< Workaround
<  - Try another compiler or update/tune your current one
<  - Remove inter-iterations dependences from your loop and make it unit-stride:
<   * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly
<   * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA)
< 
< 
< 
<       5.1.2.1.2  -  Execution units bottlenecks
<   ----------------------------------------------------------------------------------------
< 
< Found no such bottlenecks but see expert reports for more complex bottlenecks.
< 
< 
< 
< No data for this section
< 
< 
< 
<       5.1.2.1.3  -  Type of elements and instruction set
<   ----------------------------------------------------------------------------------------
< 
< No instructions are processing arithmetic or math operations on FP elements. This loop is probably writing/copying data or processing integer elements.
< 
< 
<       5.1.2.1.4  -  Matching between your loop (in the source code) and the binary loop
<   ----------------------------------------------------------------------------------------
< 
< The binary loop does not contain any FP arithmetical operations.
< The binary loop does not load or store any data.
